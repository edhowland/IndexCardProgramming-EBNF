<HTML>
<TITLE>Perl Style Regular Expressions in Prolog</TITLE>
<STYLE type="text/css">
     BODY { background: white; }
     H1.doctitle {text-align:center;}
     H4.dochead {text-align:right;}
</STYLE>
</HEAD>
<BODY>
<H1 class="doctitle">Perl Style Regular Expressions in Prolog</H1>
<H4 class="dochead">CMPT 384 Lecture Notes<BR>
Robert D. Cameron<BR>
November 29 - December 1, 1999</H4>


<H2>Case Study: Implementing Perl Style Regular Expressions</H2>
<P>
A Prolog system for processing Perl style regular expressions
can be implemented via the following steps.
<OL>
<LI>Defining the BNF grammar of Perl-style regular expressions.
<LI>Defining a Prolog representation of Perl regular expressions.
<LI>Build a DCG parser for Perl regular expressions.
<LI>Building a regular expression matcher in Prolog.
</OL>
<P>
This is a useful case study of symbolic computing in Prolog
and also an exploration of the semantics of regular expressions.



<H2>BNF Grammar of Regular Expressions</H2>
<P>
Following the precedence rules given previously, a BNF
grammar for Perl-style regular expressions can be
constructed as follows.

<TABLE>
<TR><TD>&lt;RE&gt; <TD> ::= <TD>
 &lt;union&gt;&nbsp;|  
 &lt;simple-RE&gt;</TR>
<TR><TD>&lt;union&gt; <TD> ::=<TD>&lt;RE&gt; "<CODE>|</CODE>" &lt;simple-RE&gt; 
</TR>
<TR><TD>&lt;simple-RE&gt; <TD> ::= <TD>
   &lt;concatenation&gt;&nbsp;|  &lt;basic-RE&gt;   </TR>
<TR><TD>&lt;concatenation&gt; 
<TD> ::=<TD>&lt;simple-RE&gt; &lt;basic-RE&gt;  </TR>
<TR><TD>&lt;basic-RE&gt; <TD> ::=<TD>
   &lt;star&gt;&nbsp;|  &lt;plus&gt;&nbsp;| &lt;elementary-RE&gt;   </TR>
<TR><TD>&lt;star&gt; 
<TD> ::=<TD>&lt;elementary-RE&gt; "<CODE>*</CODE>"  </TR>
<TR><TD>&lt;plus&gt; 
<TD> ::=<TD>&lt;elementary-RE&gt; "<CODE>+</CODE>"  </TR>
<TR><TD>&lt;elementary-RE&gt; <TD> ::=<TD>
   &lt;group&gt;&nbsp;|  
   &lt;any&gt;&nbsp;| &lt;eos&gt;&nbsp;|  &lt;char&gt;&nbsp;| &lt;set&gt;</TR>
<TR><TD>&lt;group&gt; <TD> ::=
<TD>"<CODE>(</CODE>" &lt;RE&gt; "<CODE>)</CODE>" </TR>
<TR><TD>&lt;any&gt; <TD> ::= <TD>"<CODE>.</CODE>"</TR>
<TR><TD>&lt;eos&gt; <TD> ::= <TD>"<CODE>$</CODE>"</TR>
<TR><TD>&lt;char&gt; <TD> ::= <TD>any non metacharacter | "\" metacharacter</TR>
<TR><TD>&lt;set&gt; <TD> ::= <TD> &lt;positive-set&gt;&nbsp;|  &lt;negative-set&gt;</TR>
<TR><TD>&lt;positive-set&gt; <TD> ::= <TD>"<CODE>[</CODE>" &lt;set-items&gt; "<CODE>]</CODE>"</TR>
<TR><TD>&lt;negative-set&gt; <TD> ::= <TD>"<CODE>[^</CODE>" &lt;set-items&gt; "<CODE>]</CODE>"</TR>
<TR><TD>&lt;set-items&gt; <TD> ::= <TD>&lt;set-item&gt; | &lt;set-item&gt; &lt;set-items&gt;</TR>
<TR><TD>&lt;set-items&gt; <TD> ::= <TD>&lt;range&gt; | &lt;char&gt;</TR>
<TR><TD>&lt;range&gt; <TD> ::= <TD>&lt;char&gt; "<CODE>-</CODE>" &lt;char&gt;</TR>
</TABLE>

<H2>Prolog Representation of Regular Expressions</H2>
<P>
To represent regular expressions as symbolic objects
in Prolog, we specify that
<code>union</code>/2,
<code>conc</code>/2,
<code>star</code>/1,
<code>plus</code>/1,
and <code>group</code>/1 represent
the five types of structured (recursively defined)
regular expression.
The symbolic atoms <code>any</code> and </code>eos</code>
represent the metacharacters "<code>.</code>" and "<code>$</code>",
while <code>char</code>/1 represents a single character.
Positive and negative sets are represented respectively
as <code>posSet</code>/1 and <code>negSet</code>/1, in which
set items are enclosed in a list.  The set items may be 
individual <code>char</code>/1 items or <code>range</code>/2
structures for character ranges.

<H2>DCG Parser for Regular Expressions</H2>
<P>
Constructing the DCG parser requires apply the left recursion
removal techniques illustrated earlier for both the
&lt;RE&gt; and &lt;basic-RE&gt; productions.
We also left factor the &lt;simple-RE&gt;
production to avoid backtracking.

<PRE>
re(Z) --> basicRE(W), reTail(W, Z).
reTail(W, Z) --> "|", basicRE(X), reTail(union(W,X), Z).
reTail(W, W) --> {true}.
basicRE(Z) --> simpleRE(W), basicREtail(W, Z).
basicREtail(W, Z) --> simpleRE(X), basicREtail(conc(W,X), Z).
basicREtail(W, W) --> {true}.
simpleRE(Z) --> elementalRE(W), simpleREtail(W, Z).
simpleREtail(W, star(W)) --> "*".
simpleREtail(W, plus(W)) --> "+".
simpleREtail(W, W) --> {true}.
elementalRE(any) --> ".".
elementalRE(group(X)) --> "(", re(X), ")".
elementalRE(eos) --> "$".
elementalRE(char(C)) --> [C], {\+(re_metachar([C]))}.
re_metachar("\\").
re_metachar("\|").
re_metachar("*").
re_metachar("+").
re_metachar("\.").
re_metachar("[").
re_metachar("$").
re_metachar("(").
re_metachar(")").
elementalRE(char(C)) --> "\\", [C], {re_metachar([C])}.
%  For sets, first try the negative set syntax.  If the "[^" recognition
%  succeeds, use cut to make sure that any subsequent failure does not
%  cause the positive set interpretation to be used.
elementalRE(negSet(X)) --> "[^", {!}, setItems(X), "]".
elementalRE(posSet(X)) --> "[", setItems(X), "]".
setItems([Item1|MoreItems]) --> setItem(Item1), setItems(MoreItems).
setItems([Item1]) --> setItem(Item1).
setItem(char(C)) --> [C], {\+(set_metachar([C]))}.
set_metachar("\\").
set_metachar("]").
set_metachar("-").
setItem(char(C)) --> "\\", [C], {set_metachar([C])}.
setItem(range(A,B)) --> setItem(char(A)), "-", setItem(char(B)).

</PRE>

<H2>Logic of Regular Expression Matching and Selection</H2>
<PRE>
%
% rematch1(RE, S, Unmatched, Selected) is true if RE matches
% a string Prefix such that S = [Prefix|Unmatched], and
% Selected is the list of substrings of Prefix that matched
% the parenthesized components of RE.

rematch1(union(RE1, _RE2), S, U, Selected) :- 
  rematch1(RE1, S, U, Selected).
rematch1(union(_RE1, RE2), S, U, Selected) :- 
  rematch1(RE2, S, U, Selected).
rematch1(conc(RE1, RE2), S, U, Selected) :- 
  rematch1(RE1, S, U1, Sel1),
  rematch1(RE2, U1, U, Sel2),
  append(Sel1, Sel2, Selected).
% Try longest match first.
rematch1(star(RE), S, U, Selected) :-
  rematch1(RE, S, U1, Sel1),
  rematch1(star(RE), U1, U, Sel2),
  append(Sel1, Sel2, Selected).
rematch1(star(_RE), S, S, []).
rematch1(plus(RE), S, U, Selected) :-
  rematch1(RE, S, U1, Sel1),
  rematch1(star(RE), U1, U, Sel2),
  append(Sel1, Sel2, Selected).
% Match a group and add it to the end of
% list of selected items from the submatch.
rematch1(group(RE), S, U, Selected) :-
  rematch1(RE, S, U, Sel1),
  append(P, U, S),
  append(Sel1, [P], Selected).

rematch1(any, [_C1|U], U, []).
% Note that the following works for matching both regular
% characters and metacharacters.  
rematch1(char(C), [C|U], U, []).

rematch1(eos, [], [], []).

rematch1(negSet(Set), [C|U], U, []) :-
  \+(charSetMember(C, Set)).

rematch1(posSet(Set), [C|U], U, []) :-
  charSetMember(C, Set).

charSetMember(C, [char(C) | _]).
charSetMember(C, [range(C1, C2) | _]) :-
  C1 =< C,
  C =< C2.
charSetMember(C, [_|T]) :- charSetMember(C, T).
</PRE>

<H2>Lexical Analysis with Regular Expressions</H2>
<UL>
<LI>Define a regular expression that matches and extracts tokens.
<LI>Repeatedly apply this expression until all input is consumed.
</UL>
<P>
The <code>tokenize</code>/3 predicate will do the whole job,
given a satisfactory regular expression!
<PRE>
%
%  tokenize(RE, Input, Output) is true if
%    - RE is the string representation of a regular expression,
%         with tokens identified by parenthesized subexpressions 
%    - Input is an input string
%    - Output is the list of tokens extracted by repeated application
%      of RE to Input.
%
tokenize(RE, Input, Output) :-
  re(Parsed_RE, RE, []),
  tokenize2(Parsed_RE, Input, Output).
  
tokenize2(_P_RE, [], []).
tokenize2(P_RE, Input, Output) :-
  rematch1(P_RE, Input, Unmatched, SelStrings),
  names(Tokens, SelStrings),
  tokenize2(P_RE, Unmatched, MoreTokens),
  append(Tokens, MoreTokens, Output).
  
names([],[]).
names([Sym1|MoreSymbols], [Str1|MoreStrings]) :-
  name(Sym1, Str1), 
  names(MoreSymbols, MoreStrings).
</PRE>
<P>
To use the tokenizer for lexical analysis, we now need only
define a regular expression that specifies the 
allowable forms of tokens and whitespace.
Tokens should be included inside parenthesized regular
expressions so they are returned; whitespace should not
be included in parenthesized expressions.  For example,
if we consider the tokens for the numeric expression grammar
described previously, an appropriate
regular expression is "<code> +|([0-9]+|\+|-)</code>".
Note that this expression defines 4 alternative string
types: (1) sequences of one or more spaces ("<code> +</code>"),
(2) sequences of one or more digits ("<code>[0-9]+</code>"),
(3) the <code>+</code> operator (which must be escaped because
it is a metacharacter), and (4) the <code>-</code> operator.
However, only the last three are selected as tokens by
inclusion within parentheses.
<P>
Finally, to use this expression in the Prolog tokenizer, the
escape character itself must be escaped due to Prolog's string
syntax conventions.
<pre>
| ?- ['/gfs1/CMPT/384/a5/regexp.pl'].
yes
| ?- tokenize(" +|([0-9]+|\\+|-)", "12 + 4 - 29", L).

L = [12,+,4,-,29] ? 
</pre>
The tokenizer does all the work!
<P>
One additional point worth considering is that you can
force Prolog to backtrack and undo decisions made by
the "longest match" rule.  The following script illustrates
what happens when each tokenization produced is
rejected by the user typing the "<code>;</code>" operator.
<pre>
| ?- tokenize(" +|([0-9]+|\\+|-)", "12 + 4 - 29", L).

L = [12,+,4,-,29] ? ;

L = [12,+,4,-,2,9] ? ;

L = [1,2,+,4,-,29] ? ;

L = [1,2,+,4,-,2,9] ? ;

no
</pre>
<H2>Concluding Remarks</H2>
<P>
The regular expression package defined here in Prolog is intended
to illustrate both the power of regular expressions
and their semantics in logical form.
It is not intended to be a practical tool. 
However, the built-in regular expression support provided
by many scripting languages (Perl, Javascript and so on),
Unix tools (emacs, ex, grep, and so on), and lexical analyzer
generators (lex, flex, flex++, and so on) are indeed practical
and can greatly simplify string processing.  
The use of regular expressions for lexical analysis is
a standard technique that is widely used in symbolic
computing applications.


</BODY>
</HTML>

